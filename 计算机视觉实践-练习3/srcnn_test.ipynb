{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ac48a13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from natsort import natsorted\n",
    "from torchvision.transforms import functional as F\n",
    "from torch import nn\n",
    "import math\n",
    "from skimage.metrics import structural_similarity\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b445af2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class SRCNN(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(SRCNN, self).__init__()\n",
    "        # Feature extraction layer.\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, (9, 9), (1, 1), (4, 4)),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # Non-linear mapping layer.\n",
    "        self.map = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, (5, 5), (1, 1), (2, 2)),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # Rebuild the layer.\n",
    "        self.reconstruction = nn.Conv2d(32, 1, (5, 5), (1, 1), (2, 2))\n",
    "\n",
    "        # Initialize model weights.\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "    # Support torch.script function.\n",
    "    def _forward_impl(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        out = self.features(x)\n",
    "        out = self.map(out)\n",
    "        out = self.reconstruction(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    # The filter weight of each layer is a Gaussian distribution with zero mean and\n",
    "    # standard deviation initialized by random extraction 0.001 (deviation is 0)\n",
    "    def _initialize_weights(self) -> None:\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.normal_(module.weight.data, 0.0, math.sqrt(2 / (module.out_channels * module.weight.data[0][0].numel())))\n",
    "                nn.init.zeros_(module.bias.data)\n",
    "\n",
    "        nn.init.normal_(self.reconstruction.weight.data, 0.0, 0.001)\n",
    "        nn.init.zeros_(self.reconstruction.bias.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4245fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bgr2ycbcr_torch(tensor: torch.Tensor, only_use_y_channel: bool) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    将 BGR 彩色图像转换为 YCbCr 彩色空间，返回 torch.Tensor 类型的结果。\n",
    "    Args:\n",
    "        tensor: 输入图像，类型为 torch.Tensor，shape 为 [batch_size, channels, height, width]。\n",
    "        only_use_y_channel: 是否只使用 Y 通道。\n",
    "    Returns:\n",
    "        转换后的图像，类型为 torch.Tensor，shape 与输入相同。\n",
    "    \"\"\"\n",
    "    if only_use_y_channel:\n",
    "        weight = torch.Tensor([[24.966], [128.553], [65.481]]).to(tensor)\n",
    "        tensor = torch.matmul(tensor.permute(0, 2, 3, 1), weight).permute(0, 3, 1, 2) + 16.0\n",
    "    else:\n",
    "        weight = torch.Tensor([[24.966, 112.0, -18.214],\n",
    "                               [128.553, -74.203, -93.786],\n",
    "                               [65.481, -37.797, 112.0]]).to(tensor)\n",
    "        bias = torch.Tensor([16, 128, 128]).view(1, 3, 1, 1).to(tensor)\n",
    "        tensor = torch.matmul(tensor.permute(0, 2, 3, 1), weight).permute(0, 3, 1, 2) + bias\n",
    "    tensor /= 255.\n",
    "    return tensor\n",
    "def ycbcr2rgb(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    将 YCbCr 彩色图像转换为 RGB 彩色空间，返回 numpy.ndarray 类型的结果。\n",
    "    Args:\n",
    "        image: 输入图像，类型为 numpy.ndarray，shape 为 [height, width, channels]。\n",
    "    Returns:\n",
    "        转换后的图像，类型为 numpy.ndarray，shape 与输入相同。\n",
    "    \"\"\"\n",
    "    image_dtype = image.dtype\n",
    "    image *= 255.\n",
    "    image = np.matmul(image, [[0.00456621, 0.00456621, 0.00456621],\n",
    "                              [0, -0.00153632, 0.00791071],\n",
    "                              [0.00625893, -0.00318811, 0]]) * 255.0 + [-222.921, 135.576, -276.836]\n",
    "\n",
    "    image /= 255.\n",
    "    image = image.astype(image_dtype)\n",
    "    return image\n",
    "def image2tensor(image: np.ndarray, range_norm: bool, half: bool) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    将 numpy.ndarray 类型的图像转换为 torch.Tensor 类型，并进行标准化和类型转换。\n",
    "    Args:\n",
    "        image: 输入图像，类型为 numpy.ndarray，shape 为 [height, width, channels]。\n",
    "        range_norm: 是否进行 [0, 1] 到 [-1, 1] 的标准化。\n",
    "        half: 是否将类型转换为 torch.half。\n",
    "    Returns:\n",
    "        转换后的图像，类型为 torch.Tensor，shape 为 [batch_size, channels, height, width]。\n",
    "    \"\"\"\n",
    "    tensor = F.to_tensor(image)\n",
    "    # Scale the image data from [0, 1] to [-1, 1]\n",
    "    if range_norm:\n",
    "        tensor = tensor.mul(2.0).sub(1.0)\n",
    "    # Convert torch.float32 image data type to torch.half image data type\n",
    "    if half:\n",
    "        tensor = tensor.half()\n",
    "    return tensor\n",
    "def bgr2ycbcr(image: np.ndarray, only_use_y_channel: bool) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    将BGR格式的图像转换为YCbCr格式的图像\n",
    "    参数:\n",
    "    - image: numpy数组, 形状为(H, W, 3), 存储BGR格式的图像\n",
    "    - only_use_y_channel: bool型变量，True表示只使用亮度(Y)通道，False表示使用亮度(Y)、色度(Cb、Cr)通道\n",
    "    返回值:\n",
    "    - numpy数组，形状为(H, W, 1) 或 (H, W, 3), 存储YCbCr格式的图像，数值范围为[0, 1]    \n",
    "    \"\"\"\n",
    "    if only_use_y_channel:\n",
    "        image = np.dot(image, [24.966, 128.553, 65.481]) + 16.0\n",
    "    else:\n",
    "        image = np.matmul(image, [[24.966, 112.0, -18.214], [128.553, -74.203, -93.786], [65.481, -37.797, 112.0]]) + [\n",
    "            16, 128, 128]\n",
    "\n",
    "    image /= 255.\n",
    "    image = image.astype(np.float32)\n",
    "    return image\n",
    "def ycbcr2bgr(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    将YCbCr格式的图像转换为BGR格式的图像\n",
    "    参数:\n",
    "    - image: numpy数组，形状为(H, W, 3)，存储YCbCr格式的图像\n",
    "    返回值:\n",
    "    - numpy数组，形状为(H, W, 3)，存储BGR格式的图像，数值范围为[0, 255]\n",
    "    \"\"\"\n",
    "    image_dtype = image.dtype\n",
    "    image *= 255.\n",
    "    image = np.matmul(image, [[0.00456621, 0.00456621, 0.00456621],\n",
    "                              [0.00791071, -0.00153632, 0],\n",
    "                              [0, -0.00318811, 0.00625893]]) * 255.0 + [-276.836, 135.576, -222.921]\n",
    "\n",
    "    image /= 255.\n",
    "    image = image.astype(image_dtype)\n",
    "    return image\n",
    "def tensor2image(tensor: torch.Tensor, range_norm: bool, half: bool) :\n",
    "    \"\"\"\n",
    "    将PyTorch张量转换为numpy数组，并转换为图像格式\n",
    "    参数:\n",
    "    - tensor: PyTorch张量，形状为(1, 3, H, W)，存储RGB格式的图像\n",
    "    - range_norm: bool型变量，表示是否需要对图像进行归一化，True表示需要进行归一化，False表示不需要进行归一化\n",
    "    - half: bool型变量，表示是否需要将数据类型转换为半精度浮点数，True表示需要转换为半精度浮点数，False表示不需要转换\n",
    "    返回值:\n",
    "    - numpy数组，形状为(H, W, 3)，存储BGR格式的图像，数值范围为[0, 255]\n",
    "    \"\"\"\n",
    "    if range_norm:\n",
    "        tensor = tensor.add(1.0).div(2.0)\n",
    "    if half:\n",
    "        tensor = tensor.half()\n",
    "    image = tensor.squeeze(0).permute(1, 2, 0).mul(255).clamp(0, 255).cpu().numpy().astype(\"uint8\")\n",
    "    return image\n",
    "def psnr(img1, img2):\n",
    "    return 10. * torch.log10(1. / torch.mean((img1 - img2) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71dc192b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing `c:\\Users\\DELL\\Desktop\\计算机视觉实践\\计算机视觉实践-练习3\\data\\Set5\\baby.png`...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_70780\\1569406781.py:44: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  downscale = transforms.Resize(int(size / 4), interpolation=Image.BICUBIC)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_70780\\1569406781.py:45: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  upscale = transforms.Resize(int(size ), interpolation=Image.BICUBIC)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_70780\\1569406781.py:74: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  ssim_metrics = structural_similarity(sr_y_image, hr_y_image, win_size=11, gaussian_weights=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baby.png  psnr:33.09375\n",
      "baby.png  ssim:0.8817651867866516\n",
      "Processing `c:\\Users\\DELL\\Desktop\\计算机视觉实践\\计算机视觉实践-练习3\\data\\Set5\\bird.png`...\n",
      "bird.png  psnr:32.0\n",
      "bird.png  ssim:0.9054357409477234\n",
      "Processing `c:\\Users\\DELL\\Desktop\\计算机视觉实践\\计算机视觉实践-练习3\\data\\Set5\\butterfly.png`...\n",
      "butterfly.png  psnr:25.140625\n",
      "butterfly.png  ssim:0.8481625318527222\n",
      "Processing `c:\\Users\\DELL\\Desktop\\计算机视觉实践\\计算机视觉实践-练习3\\data\\Set5\\head.png`...\n",
      "head.png  psnr:32.40625\n",
      "head.png  ssim:0.7781951427459717\n",
      "Processing `c:\\Users\\DELL\\Desktop\\计算机视觉实践\\计算机视觉实践-练习3\\data\\Set5\\woman.png`...\n",
      "woman.png  psnr:28.4375\n",
      "woman.png  ssim:0.8778899312019348\n",
      "PSNR: 30.22 [dB]\n",
      "SSIM: 0.8583 [u]\n"
     ]
    }
   ],
   "source": [
    "def main() -> None:\n",
    "    lr_dir=f\"./data/Set5\"#指定包含低分辨率测试图像的目录。\n",
    "    hr_dir = f\"./data/Set5\"#指定包含相应高分辨率测试图像的目录（仅用于评估）。\n",
    "    device = torch.device(\"cuda\", 0)#：指定计算设备为第一个可用的CUDA启用的GPU。\n",
    "    upscale_factor=4#：指定图像将放大的比例因子。\n",
    "    model_path='./srcnn_model/srcnn_x4-T91-7c460643.pth.tar'#指定预训练的SRCNN模型权重文件路径\n",
    "    psnr_metrics_all = 0.0\n",
    "    ssim_metrics_all = 0.0#初始化用于计算所有测试图像的PSNR和SSIM度量的变量。\n",
    "    model = SRCNN().to(device=device, memory_format=torch.channels_last)#：创建SRCNN模型实例并将其发送到计算设备。\n",
    "\n",
    "    # 从指定文件加载预训练的SRCNN模型权重。\n",
    "    checkpoint = torch.load(model_path, map_location=lambda storage, loc: storage)\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "    # 创建用于存储超分辨率实验结果的目录。\n",
    "    results_dir = os.path.join(\"srcnn_results\")\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "\n",
    "    # 将模型设置为评估模式，禁用任何在训练期间行为不同的层（如丢弃或批量归一化）\n",
    "    model.eval()\n",
    "    # ：开启半精度推理，减少存储中间激活所需的内存量并加速计算。\n",
    "    model.half()\n",
    "    # Initialize IQA metrics\n",
    "    psnr_metrics = 0.0\n",
    "    ssim_metrics = 0.0\n",
    "\n",
    "    # 获取所有低分辨率测试图像文件名的排序列表。\n",
    "    file_names = natsorted(os.listdir(lr_dir))\n",
    "    # 计算测试图像的总数。\n",
    "    total_files = len(file_names)\n",
    "\n",
    "    for index in range(total_files):\n",
    "        # 获取LR图像路径、SR图像路径、HR图像路径\n",
    "        lr_image_path = os.path.join(lr_dir, file_names[index])\n",
    "        sr_image_path = os.path.join(results_dir, f'super_resolution_{file_names[index]}')\n",
    "        hr_image_path = os.path.join(hr_dir, file_names[index])\n",
    "        print(f\"Processing `{os.path.abspath(lr_image_path)}`...\")\n",
    "        # 读取LR图像和HR图像\n",
    "        hr_image = cv2.imread(hr_image_path, cv2.IMREAD_UNCHANGED).astype(np.float32) / 255.0\n",
    "        #加载低分辨率图像，获取其宽度和高度中较小的值，并使用双三次插值将其缩小4倍。\n",
    "        lr_img = Image.open(lr_image_path)\n",
    "        size = np.min(lr_img.size)\n",
    "        downscale = transforms.Resize(int(size / 4), interpolation=Image.BICUBIC)\n",
    "        upscale = transforms.Resize(int(size ), interpolation=Image.BICUBIC)\n",
    "        #将低分辨率图像转换为numpy数组，并将其从RGB格式转换为BGR格式，以便能够保存为图像文件。\n",
    "        lr_img = downscale(lr_img)\n",
    "        lr_img=upscale(lr_img)\n",
    "        lr_image = np.array(lr_img).astype(np.float32) / 255.0\n",
    "        lr_image = cv2.cvtColor(lr_image, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(os.path.join(results_dir,f'GroundTruth_{ file_names[index]}'), hr_image * 255.0)\n",
    "        cv2.imwrite(os.path.join(results_dir,f'subsample_{ file_names[index]}'), lr_image * 255.0)\n",
    "        # 获取LR图像和HR图像的Y通道数据\n",
    "        lr_y_image = bgr2ycbcr(lr_image, True)\n",
    "        hr_y_image = bgr2ycbcr(hr_image, True)\n",
    "        # 获取HR图像的Cb和Cr通道数据\n",
    "        hr_ycbcr_image = bgr2ycbcr(hr_image, False)\n",
    "        _, hr_cb_image, hr_cr_image = cv2.split(hr_ycbcr_image)\n",
    "        # 将RGB通道图像数据转换为Tensor通道图像数据\n",
    "        lr_y_tensor = image2tensor(lr_y_image, False, True).unsqueeze_(0)\n",
    "        hr_y_tensor = image2tensor(hr_y_image, False, True).unsqueeze_(0)\n",
    "       # 将Tensor通道图像数据转移到CUDA设备上\n",
    "        lr_y_tensor = lr_y_tensor.to(device=device, memory_format=torch.channels_last, non_blocking=True)\n",
    "        hr_y_tensor = hr_y_tensor.to(device=device, memory_format=torch.channels_last, non_blocking=True)\n",
    "        with torch.no_grad():# 声明一个上下文管理器，以确保在评估模型时不会计算梯度。\n",
    "            sr_y_tensor = model(lr_y_tensor).clamp_(0, 1.0)#使用预训练的超分辨率模型将低分辨率输入图像(通过lr_y_tensor)转换为高分辨率图像(通过sr_y_tensor)，并将像素值限制在[0,1]范围内。\n",
    "        sr_y_image = tensor2image(sr_y_tensor, False, True)#将PyTorch张量转换为OpenCV图像格式，并存储生成的高分辨率图像。\n",
    "        sr_y_image = sr_y_image.astype(np.float32) / 255.0#将像素值标准化为[0,1]的范围内的浮点数。\n",
    "        sr_ycbcr_image = cv2.merge([sr_y_image, hr_cb_image, hr_cr_image])#将生成的高分辨率亮度通道与原始的彩色通道合并，形成完整的高分辨率图像。\n",
    "        sr_image = ycbcr2bgr(sr_ycbcr_image)#将YCbCr颜色空间转换回BGR颜色空间，以在屏幕上显示图像。\n",
    "        hr_y_image = tensor2image(hr_y_tensor, False, True)#将高分辨率目标图像从PyTorch张量转换为OpenCV图像格式。\n",
    "        hr_y_image = hr_y_image.astype(np.float32) / 255.0#将像素值标准化为[0,1]的范围内的浮点数\n",
    "        psnr_metrics = psnr(sr_y_tensor, hr_y_tensor).item()#计算峰值信噪比(PSNR)指标，并将其作为Tensor返回。通过.item()方法将其转换为Python float类型。\n",
    "        ssim_metrics = structural_similarity(sr_y_image, hr_y_image, win_size=11, gaussian_weights=True,\n",
    "                                             multichannel=True, data_range=1.0, K1=0.01, K2=0.03, sigma=1.5)\n",
    "        psnr_metrics_all += psnr_metrics\n",
    "        ssim_metrics_all += ssim_metrics\n",
    "        text='psnr:'+str(round(float(psnr_metrics), 3))+' ssim:'+str(ssim_metrics)#生成一个文本字符串，包含当前图像的PSNR和SSIM指标值。\n",
    "        cv2.putText(sr_image, text, (40, 50), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0,255), 1)#在生成的图像上绘制文本字符串。\n",
    "        print(file_names[index],f' psnr:{psnr_metrics}')\n",
    "        print(file_names[index], f' ssim:{ssim_metrics}')\n",
    "        cv2.imwrite(sr_image_path, sr_image * 255.0)\n",
    "    avg_psnr = 100 if psnr_metrics_all / total_files > 100 else psnr_metrics_all / total_files\n",
    "    avg_ssim = 1 if ssim_metrics_all / total_files > 1 else ssim_metrics_all / total_files\n",
    "    print(f\"PSNR: {avg_psnr:4.2f} [dB]\\n\"\n",
    "          f\"SSIM: {avg_ssim:4.4f} [u]\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc5d90e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
