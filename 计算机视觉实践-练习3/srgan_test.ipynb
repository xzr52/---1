{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ac48a13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from natsort import natsorted\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "from PIL import Image\n",
    "import math\n",
    "from skimage.metrics import structural_similarity\n",
    "from typing import Any\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn import functional as F_torch\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from torchvision.models.feature_extraction import create_feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b445af2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def make_directory(dir_path: str) -> None:\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "def tensor_to_image(tensor:torch.Tensor, range_norm: bool, half: bool) :\n",
    "    if range_norm:\n",
    "        tensor = tensor.add(1.0).div(2.0)\n",
    "    if half:\n",
    "        tensor = tensor.half()\n",
    "\n",
    "    image = tensor.squeeze(0).permute(1, 2, 0).mul(255).clamp(0, 255).cpu().numpy().astype(\"uint8\")\n",
    "\n",
    "    return image\n",
    "def psnr(img1, img2):\n",
    "    return 10. * torch.log10(1. / torch.mean((img1 - img2) ** 2))\n",
    "def image_to_tensor(image: ndarray, range_norm: bool, half: bool):\n",
    "    # Convert image data type to Tensor data type\n",
    "    tensor = torch.from_numpy(np.ascontiguousarray(image)).permute(2, 0, 1).float()\n",
    "    # Scale the image data from [0, 1] to [-1, 1]\n",
    "    if range_norm:\n",
    "        tensor = tensor.mul(2.0).sub(1.0)\n",
    "    # Convert torch.float32 image data type to torch.half image data type\n",
    "    if half:\n",
    "        tensor = tensor.half()\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4245fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRResNet(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "            out_channels: int,\n",
    "            channels: int,\n",
    "            num_rcb: int,\n",
    "            upscale_factor: int\n",
    "    ) -> None:\n",
    "        super(SRResNet, self).__init__()\n",
    "        #低频信息提取层：使用一个包含一个卷积层和PReLU激活函数的Sequential对象来提取输入图像的低频信息。\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, channels, (9, 9), (1, 1), (4, 4)),\n",
    "            nn.PReLU(),\n",
    "        )\n",
    "\n",
    "        #高频信息提取块：使用了多个残差卷积块_ResidualConvBlock来提取输入图像的高频信息。\n",
    "        trunk = []\n",
    "        for _ in range(num_rcb):\n",
    "            trunk.append(_ResidualConvBlock(channels))\n",
    "        self.trunk = nn.Sequential(*trunk)\n",
    "\n",
    "        #高频线性融合层：使用了一个包含一个卷积层、批归一化和PReLU激活函数的Sequential对象对高频信息进行线性融合。\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, (3, 3), (1, 1), (1, 1), bias=False),\n",
    "            nn.BatchNorm2d(channels),\n",
    "        )\n",
    "\n",
    "        #放大块：使用了多个_UpsampleBlock来将低分辨率图像放大到目标分辨率。这个过程中，每个_UpsampleBlock都包含了一个卷积层、像素洗牌(PixelShuffle)和PReLU激活函数。\n",
    "        upsampling = []\n",
    "        if upscale_factor == 2 or upscale_factor == 4 or upscale_factor == 8:\n",
    "            for _ in range(int(math.log(upscale_factor, 2))):\n",
    "                upsampling.append(_UpsampleBlock(channels, 2))\n",
    "        elif upscale_factor == 3:\n",
    "            upsampling.append(_UpsampleBlock(channels, 3))\n",
    "        self.upsampling = nn.Sequential(*upsampling)\n",
    "\n",
    "       #重建块：使用一个卷积层来将放大后的图像进行重建，并使用clamp函数将像素值限制在0到1之间。\n",
    "        self.conv3 = nn.Conv2d(channels, out_channels, (9, 9), (1, 1), (4, 4))\n",
    "\n",
    "        # Initialize neural network weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)\n",
    "\n",
    "    # Support torch.script function\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        out1 = self.conv1(x)\n",
    "        out = self.trunk(out1)\n",
    "        out2 = self.conv2(out)\n",
    "        out = torch.add(out1, out2)\n",
    "        out = self.upsampling(out)\n",
    "        out = self.conv3(out)\n",
    "\n",
    "        out = torch.clamp_(out, 0.0, 1.0)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _initialize_weights(self) -> None:\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.constant_(module.bias, 0)\n",
    "            elif isinstance(module, nn.BatchNorm2d):\n",
    "                nn.init.constant_(module.weight, 1)\n",
    "class _UpsampleBlock(nn.Module):\n",
    "    def __init__(self, channels: int, upscale_factor: int) -> None:\n",
    "        super(_UpsampleBlock, self).__init__()\n",
    "        self.upsample_block = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels * upscale_factor * upscale_factor, (3, 3), (1, 1), (1, 1)),\n",
    "            nn.PixelShuffle(2),\n",
    "            nn.PReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        out = self.upsample_block(x)\n",
    "\n",
    "        return out\n",
    "class _ResidualConvBlock(nn.Module):\n",
    "    def __init__(self, channels: int) -> None:\n",
    "        super(_ResidualConvBlock, self).__init__()\n",
    "        self.rcb = nn.Sequential(\n",
    "            nn.Conv2d(channels, channels, (3, 3), (1, 1), (1, 1), bias=False),\n",
    "            nn.BatchNorm2d(channels),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(channels, channels, (3, 3), (1, 1), (1, 1), bias=False),\n",
    "            nn.BatchNorm2d(channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.rcb(x)\n",
    "\n",
    "        out = torch.add(out, identity)\n",
    "\n",
    "        return out\n",
    "def srresnet_x4(**kwargs: Any) -> SRResNet:\n",
    "    model = SRResNet(upscale_factor=4, **kwargs)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71dc192b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing `c:\\Users\\DELL\\Desktop\\计算机视觉实践\\计算机视觉实践-练习3\\data\\Set5\\baby.png`...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_33380\\869397729.py:44: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  downscale = transforms.Resize(int(size / 4), interpolation=Image.BICUBIC)\n",
      "e:\\anaconda\\lib\\site-packages\\torchvision\\transforms\\transforms.py:332: UserWarning: Argument 'interpolation' of type int is deprecated since 0.13 and will be removed in 0.15. Please use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_33380\\869397729.py:62: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  ssim_metrics = structural_similarity(sr_image.astype(np.float32) / 255.0, gt_image, win_size=11, gaussian_weights=True,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baby.png  psnr:30.62220573425293\n",
      "baby.png  ssim:0.8199921250343323\n",
      "Processing `c:\\Users\\DELL\\Desktop\\计算机视觉实践\\计算机视觉实践-练习3\\data\\Set5\\bird.png`...\n",
      "bird.png  psnr:29.83331871032715\n",
      "bird.png  ssim:0.857977569103241\n",
      "Processing `c:\\Users\\DELL\\Desktop\\计算机视觉实践\\计算机视觉实践-练习3\\data\\Set5\\butterfly.png`...\n",
      "butterfly.png  psnr:25.211177825927734\n",
      "butterfly.png  ssim:0.8504059314727783\n",
      "Processing `c:\\Users\\DELL\\Desktop\\计算机视觉实践\\计算机视觉实践-练习3\\data\\Set5\\head.png`...\n",
      "head.png  psnr:28.8527774810791\n",
      "head.png  ssim:0.6636013984680176\n",
      "Processing `c:\\Users\\DELL\\Desktop\\计算机视觉实践\\计算机视觉实践-练习3\\data\\Set5\\woman.png`...\n",
      "woman.png  psnr:27.815959930419922\n",
      "woman.png  ssim:0.8716802000999451\n",
      "PSNR: 28.47 [dB]\n",
      "SSIM: 0.8127 [u]\n"
     ]
    }
   ],
   "source": [
    "def main() -> None:\n",
    "    device = torch.device(\"cuda\", 0)#指定计算设备为第一个可用的CUDA启用的GPU。\n",
    "    lr_dir = f\"./data/Set5\"#指定包含低分辨率测试图像的目录。\n",
    "    sr_dir = f\"./srgan_results/\"#创建用于存储超分辨率实验结果的目录。\n",
    "    gt_dir = f\"./data/Set5\"#指定包含相应高分辨率测试图像的目录（仅用于评估）。\n",
    "    g_model_weights_path='./srgan_model/SRGAN_x4-ImageNet-8c4a7569.pth.tar'#指定预先训练的SRResNet模型权重文件路径。\n",
    "\n",
    "    g_model = SRResNet(in_channels=3,upscale_factor=4,\n",
    "                                            out_channels=3,\n",
    "                                            channels=64,\n",
    "                                            num_rcb=16)#创建一个SRResNet模型实例，并将其发送到计算设备。\n",
    "    g_model = g_model.to(device=device)#将SRResNet模型实例移到指定计算设备上。\n",
    "\n",
    "    checkpoint = torch.load(g_model_weights_path, map_location=lambda storage, loc: storage)#从指定文件加载预先训练的SRResNet模型权重。\n",
    "    g_model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "    make_directory(sr_dir)#如果目录不存在，则创建用于存储超分辨率实验结果的目录。\n",
    "    g_model.eval()#将模型设置为评估模式\n",
    "    #初始化变量，用于计算每个测试图像的PSNR和SSIM指标以及所有测试图像的指标。\n",
    "    psnr_metrics = 0.0\n",
    "    psnr_metrics_all = 0.0\n",
    "    ssim_metrics_all = 0.0\n",
    "    # ：获取所有低分辨率测试图像文件名的排序列表。\n",
    "    file_names = natsorted(os.listdir(lr_dir))\n",
    "    # 计算测试图像的总数。\n",
    "    total_files = len(file_names)\n",
    "\n",
    "    for index in range(total_files):#迭代处理所有测试图像。\n",
    "        # 获取LR图像路径、SR图像路径、HR图像路径\n",
    "        lr_image_path = os.path.join(lr_dir, file_names[index])\n",
    "        sr_image_path = os.path.join(sr_dir, file_names[index])\n",
    "        gt_image_path = os.path.join(gt_dir, file_names[index])\n",
    "        #加载高分辨率图像，将其转换为numpy数组并归一化到0到1之间，然后将其转换为PyTorch张量，并添加批处理维度。\n",
    "        gt_img = Image.open(gt_image_path)\n",
    "        gt_image = np.array(gt_img).astype(np.float32) / 255.0\n",
    "        gt_tensor=image_to_tensor(gt_image, False, False).unsqueeze_(0)\n",
    "\n",
    "        gt_rgb_image = cv2.cvtColor(gt_image, cv2.COLOR_RGB2BGR)#将高分辨率图像从RGB格式转换为BGR格式，以便能够保存为图像文件。\n",
    "        cv2.imwrite(os.path.join(sr_dir, f'GroundTruth_{ file_names[index]}'), gt_rgb_image*255)#将高分辨率图像保存为文件，文件名前缀为\"GroundTruth_\"。\n",
    "        #加载低分辨率图像，获取其宽度和高度中较小的值，并使用双三次插值将其缩小4倍。\n",
    "        lr_img = Image.open(lr_image_path)\n",
    "        size = np.min(lr_img.size)\n",
    "        downscale = transforms.Resize(int(size / 4), interpolation=Image.BICUBIC)\n",
    "        #将低分辨率图像转换为numpy数组，并将其从RGB格式转换为BGR格式，以便能够保存为图像文件。\n",
    "        lr_img = downscale(lr_img)\n",
    "        lr_image = np.array(lr_img)\n",
    "        lr_rgb_image = cv2.cvtColor(lr_image, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(os.path.join(sr_dir, f'subsample_4_{file_names[index]}'), lr_rgb_image)#将低分辨率图像保存为文件，文件名前缀为\"subsample_4_\"。\n",
    "        lr_tensor = image_to_tensor(lr_image, False, False).unsqueeze_(0)#将低分辨率图像转换为PyTorch张量，并添加批处理维度。\n",
    "        #将输入的低分辨率图像LR表示为PyTorch张量，然后将内存格式设置为通道优先（channels-last）的方式，移动到指定的GPU设备上，并将所有像素值除以255.0，以将它们缩放到[0,1]范围内\n",
    "        lr_tensor = lr_tensor.to(device=device, memory_format=torch.channels_last, non_blocking=True)/255.0\n",
    "        gt_tensor = gt_tensor.to(device=device, memory_format=torch.channels_last, non_blocking=True)\n",
    "        # Only reconstruct the Y channel image data.\n",
    "        with torch.no_grad():#使用with语句块，以避免在反向传播时计算梯度。在这个语句块中的操作不会影响模型的梯度计算。\n",
    "            sr_tensor = g_model(lr_tensor)#通过调用预训练的超分辨率模型g_model来对低分辨率图像LR进行重建，得到超分辨率图像SR的张量表示sr_tensor。\n",
    "\n",
    "        #将SR图像的张量表示sr_tensor转换为OpenCV格式的图像表示sr_image，以便于后续的处理和保存。\n",
    "        sr_image = tensor_to_image(sr_tensor, False, True)\n",
    "        # Cal IQA metrics\n",
    "        psnr_metrics = psnr(sr_tensor, gt_tensor)#：计算SR图像和GT图像之间的PSNR指标，其中psnr()是一个自定义函数，输入为张量表示的SR和GT图像，输出为它们之间的PSNR值。\n",
    "        ssim_metrics = structural_similarity(sr_image.astype(np.float32) / 255.0, gt_image, win_size=11, gaussian_weights=True,\n",
    "                                             multichannel=True, data_range=1.0, K1=0.01, K2=0.03, sigma=1.5)\n",
    "        #计算SR图像和GT图像之间的SSIM指标，其中structural_similarity()是scikit-image库中实现的计算SSIM的函数，它的输入为SR和GT图像的OpenCV格式表示，输出为它们之间的SSIM值\n",
    "        psnr_metrics_all += psnr_metrics\n",
    "        ssim_metrics_all += ssim_metrics\n",
    "        print(file_names[index], f' psnr:{psnr_metrics}')\n",
    "        print(file_names[index], f' ssim:{ssim_metrics}')\n",
    "        sr_image = cv2.cvtColor(sr_image, cv2.COLOR_RGB2BGR)#将SR图像从RGB格式转换为BGR格式，以便于后续的保存。\n",
    "        text='psnr:'+str(round(float(psnr_metrics.cpu()), 3))+' ssim:'+str(ssim_metrics)\n",
    "        cv2.putText(sr_image, text, (40, 50), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0,255), 1)#在SR图像上添加文字标签，标注PSNR和SSIM指标的数值。\n",
    "        cv2.imwrite(os.path.join(sr_dir, f'super_resolution_{file_names[index]}'), sr_image)\n",
    "\n",
    "    avg_psnr = 100 if psnr_metrics_all / total_files > 100 else psnr_metrics_all / total_files\n",
    "    avg_ssim = 1 if ssim_metrics_all / total_files > 1 else ssim_metrics_all / total_files\n",
    "\n",
    "    print(f\"PSNR: {avg_psnr:4.2f} [dB]\\n\"\n",
    "          f\"SSIM: {avg_ssim:4.4f} [u]\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc5d90e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
